{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ElasticSearch\n",
    "\n",
    "In this notebook we have created a search engine using ElasticSearch. \n",
    "\n",
    "For our own reference:\n",
    "* Literature: <https://www.elastic.co/guide/en/elasticsearch/guide/current/index.html>\n",
    "* Telegraaf XML documents: http://data.politicalmashup.nl/arjan/telegraaf/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a search engine for the telegraaf newspaper collection using eg ElasticSearch. Make facets for years and document types. Pay attention to telephone numbers (in mini advertisements). Hieronder een voorbeeld van 1 document (= 1 artikeltje).\n",
    "Je ziet dat er zelfs een link naar de bron tekst (als plaatje) instaat. De URL linked door naar de nieuwe url http://www.delpher.nl/nl/kranten/view?identifier=ddd%3A010563762%3Ampeg21%3Aa0005&coll=ddd ElasticSearch gebruikt een JSON formaat als invoer, en dit is dus triviaal om te zetten naar JSON.\n",
    "\n",
    "Each of the following points must be addressed. Create a seperate page on the wiki for each point. Make sure these pages can be found from the menu of your wiki. Explain what you did, and exemplify with links to screenshots/a working system.\n",
    "\n",
    "* Search as we know it from Google. Give a result page (SERP), with links to the documents and some description of each hit.\n",
    "* Advanced search. Let a user be able to search in several fields, also in several fields simulteanously. Queries like \"return kamervragen by Wilders about XXX with an answer about YYY in the period ZZZ\" should be possible. (For the \"Telegraaf\" collectie, let the user search in both title and tekst fields)\n",
    "* Do one of the following:\n",
    "    1. Represent the hits of a query with a wordcloud of 25-50 informative words. The wordcloud should somehow summarise what the collection has to say about the query. You may think of these words as words that you could add to the query in order to improve recall (blind relevance feedback/query expansion).\n",
    "    2. Represent each document (a kamervraag) with a word-cloud. Also make word-clouds for the question and for the answer. EXAMPLE: The html files in http://data.politicalmashup.nl/arjan/odeii/data_as_html/ contain such wordcloud summaries, which work rather well.   \n",
    "\n",
    "You can use several techniques to get rid of high frequency, but meaningless words: of course IDF, but also mutual information (see 13.5.1), or of course the technique from the paper by Kaptein et al on wordclouds.\n",
    "\n",
    "* Give next to a traditional list of results, a timeline in which you indicate how many hits there are over time.\n",
    "* Give next to the traditional list of results, a table with the number of hits for each political party. Link the party names, which should result in only selecting the hits \"ingediend\" by members of that party. (Faceted Search) (For the \"Telegraaf\" collectie, use the dc:subject element as facet values.)\n",
    "* Evaluate your results Let 2 persons assess the relevancy of the top 10 documents for 5 different queries. Compute Cohen's kappa. Determine the average precision at 10 for your system based on these 10 queries, and the two relevance assesments. Also plot the P@10 (for both judges) for each query, showing differences in hard and easy queries. Describe clearly how you solved differences in judgements. \n",
    "Create your queries in the following format:\n",
    "\n",
    "                    <topic number=\"6\"  >\n",
    "          <query>kcs</query>\n",
    "          <description>Find information on the Kansas City Southern railroad.\n",
    "          </description>\n",
    "           \n",
    "        </topic>\n",
    "\n",
    "        <topic number=\"16\"  >\n",
    "          <query>arizona game and fish</query>\n",
    "          <description>I'm looking for information about fishing and hunting\n",
    "          in Arizona.\n",
    "          </description>\n",
    "           \n",
    "        </topic>\n",
    "                \n",
    "\n",
    "So, both provide the actual query, and a description of the information need that was behind the query.\n",
    "Give a small set of clear guidelines for judging the results, and let your judges follow these guidelines.\n",
    "It is far more interesting to have difficult queries (both for the search engine and for the judges) than to have queries on which all ten retrieved documents are relevant. So, try to create a good list of information needs.\n",
    "\n",
    "* Change the ranking of your system, compute the average precision at 10 using your 10 queries, compare the results to your old system, and EXPLAIN what is going on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Search Engine\n",
    "\n",
    "Before running ES run: \n",
    "\n",
    "    export ES_HEAP_SIZE=Half_RAM\n",
    "\n",
    "where Half_RAM is half your ram\n",
    "\n",
    "AND: \n",
    "in /config/elasticsaerch.yml add \n",
    "indices.memory.index_buffer_size: 50% \n",
    "(Still need to check if this makes a difference)\n",
    "\n",
    "To start the Elastic searh serive, please run the following code in commandline:\n",
    "\n",
    "    ./elasticsearch-2.4.1/bin/elasticsearch --node.name telegraaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate connection to the Elastic Search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "\n",
    "HOST = 'http://localhost:9200/'\n",
    "es = Elasticsearch(hosts=[HOST])\n",
    "\n",
    "# If code runs, the connection is made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator to read Telegraaf XML and add them to the ES database\n",
    "\n",
    "A generator makes it possible to immediately put the XML files/documents into the ES databse\n",
    "\n",
    "* Remove high frequency, but meaningless words\n",
    "\n",
    "You can use several techniques to get rid of high frequency, but meaningless words: of course IDF, but also mutual information (see 13.5.1), or of course the technique from the paper by Kaptein et al on wordclouds.\n",
    "\n",
    "    Possibly also create an inverted index at this point? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "from os import listdir\n",
    "from os.path import isfile\n",
    "\n",
    "def read(doc):\n",
    "    '''\n",
    "    return a generator for the date, subject(type), \n",
    "    title, and text for each item in the given year. \n",
    "    '''    \n",
    "    for date,subject, title, text, identifier in zip(doc.find_all('date'), doc.find_all('subject'), \n",
    "                                                     doc.find_all('title'), doc.find_all('text'),\n",
    "                                                     doc.find_all('identifier')):\n",
    "            yield (date.text,subject.text,title.text,text.text,identifier.text)\n",
    "\n",
    "documents = ['./Telegraaf/'+i for i in listdir('./Telegraaf') if not isfile(i)]\n",
    "soup_documents = [BeautifulSoup(open(year,\"r\"),\"xml\") for year in documents]\n",
    "\n",
    "# Create the generator for the bulk importer\n",
    "# I'm not sure if it's a good idea to use _type here as a subject (which is artcle or advertisement, or more...)\n",
    "# The score calculation for the Elastic Search database uses whole-index statistics. \n",
    "# If you're searching a subsection this will alter the scores! WE WILL NEED TO KEEP THIS IN MIND.\n",
    "#k = ({'_type':subject, '_index':'telegraaf','_source':{'year':date[:4], 'date':date[5:], 'title':title, 'text':text}} \n",
    "#    for year in documents for (date,subject,title,text) in read(year))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate ES database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "health status index     pri rep docs.count docs.deleted store.size pri.store.size \r\n",
      "yellow open   telegraaf   5   1     157546            0    345.8mb        345.8mb \r\n",
      "yellow open   megacorp    5   1          0            0       800b           800b \r\n"
     ]
    }
   ],
   "source": [
    "# List of all indices\n",
    "! curl 'localhost:9200/_cat/indices?v'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'acknowledged': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete any pre-excisting index\n",
    "es.indices.delete(index='telegraaf', ignore=[404,400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'acknowledged': True}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the telegraaf index in our telegraaf node\n",
    "es.indices.create(index='telegraaf', ignore=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'acknowledged': True}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn refresh off to speed up bulk import\n",
    "es.indices.put_settings(index='telegraaf',body={\"index\" : \n",
    "                                            {\"refresh_interval\" : \"-1\"\n",
    "                                            }\n",
    "                                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test with chunk size = 500 and max_chunk_bytes = 15728640 \n",
      "Starting time: 1477062060.45\n",
      "Finished 0.307443857193\n",
      "Finished 52.7827241421\n",
      "Finished 3.96766901016\n",
      "Finished 15.3635549545\n",
      "Finished 2.05416107178\n",
      "Done: 74.4765508175\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#Import the information into the database\n",
    "# The generator can only be used once. So this code will only work once. \n",
    "print \"Test with chunk size = 500 and max_chunk_bytes = 15728640 \"\n",
    "# helper.parallel_bulk might increase the speed even more!!!\n",
    "\n",
    "def bulk_all(documents):\n",
    "    start = time.time()\n",
    "    print \"Starting time:\", start\n",
    "\n",
    "    k = ({'_type':subject, '_index':'telegraaf','_source':{'year':date[:4], \n",
    "         'date':date[5:], 'title':title, 'text':text}}\n",
    "          for doc in documents[:5] for (date,subject,title,text,identifier) in read(doc))\n",
    "    for ok in helpers.parallel_bulk(es,k, chunk_size=500,max_chunk_bytes=15728640):\n",
    "        continue\n",
    "    end_doc =time.time()\n",
    "    print \"Finished\", (end_doc-start)\n",
    "\n",
    "def bulk_per_doc(documents):\n",
    "    start = time.time()\n",
    "    print \"Starting time:\", start\n",
    "\n",
    "    for i in documents[:5]:\n",
    "        start_doc = time.time()\n",
    "        k = ({'_type':subject, '_id':identifier, '_index':'telegraaf','_source':{'year':date[:4], \n",
    "             'date':date[5:], 'title':title, 'text':text}}\n",
    "             for (date,subject,title,text,identifier) in read(i))\n",
    "        for ok in helpers.parallel_bulk(es,k,chunk_size=500,max_chunk_bytes=15728640):\n",
    "            continue\n",
    "        end_doc =time.time()\n",
    "        print \"Finished\", (end_doc-start_doc)\n",
    "        end = time.time()\n",
    "    print \"Done:\", end - start\n",
    "        \n",
    "bulk_per_doc(soup_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'acknowledged': True}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the refresh rate back to default\n",
    "es.indices.put_settings(index='telegraaf',body={\"index\" : \n",
    "                                            {\"refresh_interval\" : \"1s\"\n",
    "                                            }\n",
    "                                       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Speed improvements/performance: \n",
    "# - bootstrap.mlockall: true in config of the file \n",
    "# (make sure  ES_HEAP_SIZE is large enough) \n",
    "# Parsing whole document xml.cElementTree.parse()\n",
    "# Streaming the xml document: xml.sax.reader.html\n",
    "\n",
    "# import xml.etree.ElementTree as etree\n",
    "# for event, elem in etree.iterparse(xmL, events=('start', 'end', 'start-ns', 'end-ns')):\n",
    "#  print event, elem\n",
    "# http://boscoh.com/programming/reading-xml-serially.html\n",
    "# Event handlers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query system \n",
    "\n",
    "* Normalise query\n",
    "* Get right tokens from the query. Use patterns to split up the query in parts? \n",
    "* Put them in the right representation for ES search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def search(query, advanced=False):\n",
    "    '''\n",
    "    Given a query it returns a SERP with rakings based on the score\n",
    "    '''\n",
    "    if advanced:\n",
    "        q = {\"query\": \n",
    "                {\"filtered\": \n",
    "                    {\"query\": {\n",
    "                        \"multi_match\": \n",
    "                            {\"query\" : query[1],\n",
    "                             \"type\" : \"cross_fields\",  # with 'and' operator \n",
    "                             \"fields\" : ['title', 'text'],\n",
    "                             \"operator\" : 'and'\n",
    "                            }\n",
    "                        },\n",
    "                     \"filter\": \n",
    "                        {\"bool\" : \n",
    "                            {\"must\" : [{\"term\": {\"year\": query[2]}},{\"term\": {\"_type\": query[0]}}]\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        res = es.search(index='telegraaf', size=10, body=q)\n",
    "        print res\n",
    "    else:\n",
    "        # filter_path can help reduce the amount of data that is returned by the es.search\n",
    "        # The query context is for how well the document fits the query\n",
    "        # The filter context is a boolean context. Does it match or not.\n",
    "        # example: Does this timestamp fall into the range 2015 to 2016?\n",
    "        #\n",
    "        \n",
    "        # The outer 'query': is necessary to show that this is the query.  \n",
    "        q = {'query':\n",
    "                {'multi_match':\n",
    "                    {'query' : query,\n",
    "                     'type' : 'cross_fields',  # with 'and' operator \n",
    "                     'fields' : ['title', 'text'],\n",
    "                     'operator' : 'and'\n",
    "                     }\n",
    "                 }\n",
    "             }\n",
    "        # In other words, all terms must be present in at least one field for a document to match.\n",
    "        res = es.search(index='telegraaf', size=10, body=q)\n",
    "        print res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'hits': {u'hits': [{u'_score': 1.2368431, u'_type': u'artikel', u'_id': u'AVfio6_4YswG1S9go2MY', u'_source': {u'date': u'03-01', u'text': u't', u'year': u'1923', u'title': u'HEVIGE STORM AAN DE ENGELSCHE KUST. Een stoomschip door de hemanning verlaten.'}, u'_index': u'telegraaf'}], u'total': 1, u'max_score': 1.2368431}, u'_shards': {u'successful': 5, u'failed': 0, u'total': 5}, u'took': 2, u'timed_out': False}\n"
     ]
    }
   ],
   "source": [
    "search('stoomschip engelsche')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result page function\n",
    "\n",
    "* Take query output and use score to order result on a Search Engine Result Page (SERP).\n",
    "* Return title, link, and description of each hit\n",
    "\n",
    "-> The description can be a word cloud of 20-25 most informative words. Represent the hits of a query with a wordcloud of 25-50 informative words. The wordcloud should somehow summarise what the collection has to say about the query. You may think of these words as words that you could add to the query in order to improve recall (blind relevance feedback/query expansion). \n",
    "\n",
    "\n",
    "Additions\n",
    "* A timeline with the amount of hits over time\n",
    "* A table with the number of hits for each political party. Link the party names, which should result in only selecting the hits \"ingediend\" by members of that party. (Faceted Search) (For the \"Telegraaf\" collectie, use the dc:subject element as facet values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Search\n",
    "\n",
    "The query system will have to be changed to implement this\n",
    "\n",
    "* Make multiple fields searchable:\n",
    "    * Title \n",
    "    * Tekst\n",
    "    * Year?\n",
    "    \n",
    "Let a user be able to search in several fields, also in several fields simulteanously. Queries like \"return kamervragen by Wilders about XXX with an answer about YYY in the period ZZZ\" should be possible. (For the \"Telegraaf\" collectie, let the user search in both title and tekst fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_years = list(set( document.date.get_text()[:4]\n",
    "                    for document in soup_documents ))\n",
    "\n",
    "unique_doc_types = list(set( subject.get_text()\n",
    "                       for document in soup_documents\n",
    "                       for subject in document.find_all('subject')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, u'mandaten', 1]\n",
      "[u'artikel', u'mandaten', u'1922']\n"
     ]
    }
   ],
   "source": [
    "from formlayout import fedit, FormDialog\n",
    "\n",
    "query = fedit([('Document type',[0]+unique_doc_types),\n",
    "               ('Zoektermen',''),\n",
    "               ('Jaar publicatie',[0]+unique_years)], \n",
    "               title=\"Telegraaf zoekmachine\", \n",
    "               comment=\"Wat voor krantenartikel zoek je?\")\n",
    "\n",
    "print query\n",
    "\n",
    "query[0] = unique_doc_types[query[0]]\n",
    "query[2] = unique_years[query[2]]\n",
    "\n",
    "print query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'hits': {u'hits': [{u'_score': 2.9305606, u'_type': u'artikel', u'_id': u'ddd:010563557:mpeg21:p001:a0002', u'_source': {u'date': u'11-29', u'text': u'i', u'year': u'1922', u'title': u'Sovjet-Rusland en de mandaten over Syri\\xeb, Palestina en Mesopotami\\xeb.'}, u'_index': u'telegraaf'}, {u'_score': 1.3677711, u'_type': u'artikel', u'_id': u'ddd:010563560:mpeg21:p006:a0159', u'_source': {u'date': u'11-30', u'text': u\"DANZIG. ?.<) Nov. \\u2014 Volgens een bericM aft ' Kowno hebben de Poolschen en Joodsche frac- ' \\u25a0ties in den Landdag van Kaamt) geprotearteerd de onrechtvaardige verdeeling \\xbb ! mandaten der waarna zij te \\u2022 ! zutiea de zittlngza i\", u'year': u'1922', u'title': u'De Landdag van Kowno.'}, u'_index': u'telegraaf'}, {u'_score': 0.9130335, u'_type': u'artikel', u'_id': u'ddd:010563575:mpeg21:p002:a0037', u'_source': {u'date': u'12-09', u'text': u\"Het plan van do\\xab ij ka-hen bondskanselier S tn den N Raad spoed:. we verkie.- te doen all afgr-vaardiedta, rsa \\u25a0 vindt \\u2014 naar de \\u201eKolt: neemt a \\xabtemmjn-r, en dat ohristelijk-eocialcn van rVeenen. andere bo-idsia \\u2022 en de groot-Da tegenstaiKi: toont zich onverschillig, minderng van het aantal mandaten. !. iar uit schiedt en waardoor vooral tijen noar I \\xablen worden, \\u2022 deze partij affgeweriDe sociaai-denxicraten betitelen verkiezingen, o; te houd\\u201ekhafc van het ... s door de rnische crisis, sterk en 1e conclusie, dat o ie ergste -en die der I aar de Duitsche daard \\u2022 larvdbonri. die als een onderafdeetirg va:. Rijkst-oerenboDd word' '\", u'year': u'1922', u'title': u'De kwestie der nieuwe verkiezingen in Oostenrijk.'}, u'_index': u'telegraaf'}, {u'_score': 0.33850607, u'_type': u'artikel', u'_id': u'ddd:010563579:mpeg21:p006:a0144', u'_source': {u'date': u'12-12', u'text': u'iVan on RAVENHAGE, vaa bi \\u201efeature\" \\xaban in verband met eer dezen , waren de .al waren zii perskamer h.ik;. -, heelen .: lende samt: iehten. Itadek voerrt-- er het hoog\\xbb woord. \\xbben spot om zijn -smond hoi wi rins \\u25a0 wij vandaag den naam van Karl Rade! voor de laatste maai ln onze verslagen - - noemd. I\"\\' drie -roo:, rapporten zijn vanda.i le drie aehti r elkaar \\u25a0 opdat de a issii\\'S niet al te : rhaling z.\\'tllen kunnen verval - l\\'-n. Daarmede \\'net rwaanept:nt van het roncre- : __ \\u201eti. . gen*aanvangen en waa-rbij het ongetwijfeld nu en dan warm zal toega., voorproefje daarvan k- D de vnorle, dat ieder debater :. minuten spreektijd zou krijgen. Ploi.- pannen stilt\\xbb\\' stuk en in den Kransrh-Belgischen hoek regende het protesten: \\u201eMais ce nest pas vn congres sa, c\\'e.n de la blague!\" riep Renaudel woedend uit ..Twintig : .n lang niet vnldoende\\'\\' nep een andere Fransehman. en hij voecde er, gelukkig iets zaciht\\xbb r. aan toe: \\u201esurtout quan.l il faudra r\\xe9pondre aux toch\\xbb Pai.s daar lag h.t: Hes borb.es* woord was er uit voor de sprekir hel wisi . -: ook naader, dat hij het ir.-wild had. He was even \\'n pijn\\'ijk moment Kn al klonk he scherper dan het wellicht bedoeld was, ons klonk het toch in de noren als het prar-i van een stonnaehtige rhapsodie. Maar overlgi ns was d\\xbb stemming van het congres tot nu toe kalm en waardig, h des te opmerkelijker is daar er in dit congr. .- zooveel uiteenloopoti mgen en keerittgen vertegenwoordigd zijn. Achter de schermen wordt evea hard gewerkt als in hel eoa 1 Vanavond zijn er :: ntraal niet minder dan drie conferenties Zr.n.i -.avond m een gezamenlijke vergadering van de Tweede en Twee-en-een-ha!f . itkraale de fusie tusschen beide beklonken w\\xbb rd, zoo vergaderde vanavond de leden van de laatst genoemde Internationale om de \\xaban uitvoering van da; besluit ie b Professor Otlet. uit Brussel, heeft voorts alle vet regen woord. - gers van paeif.sti-ch<> organisaties Lot e. r. oonferenTie uit* - -i slotte heeft vanavond een bijeenkomst van onderwijzers uit verschillende landen plaats, welke leid. tot de oprichting van een onderwijzers-internat 101 .. \\u25a0 in verband met ri geest welke naar ii van het congres voortaan hrt onderwijs, en meer :n \\'t bijzonder hei geschieden;s-onderwijs, zal dienen te bebeersc_ien. . a a \\'\\u2022-GRAVENHAGE 11 I\\xbb \\u2022welke de heer Arthur Henderson hield voor het Internationale Vredescongres, ontleenen wij nog het volgende I\" Volkenbond is de toetssteen van een wezenlijke vredespolitiek. Op het oogcnbilk is vle Volkenbond niet aneters dan het instrument van de geallieerde mogendheden. (Instemming). Dit moet veranderen. Bovendien moet de Volkenbondsve.rgadering de hoogste autorite, van \\xablen Bond wordt nbondsraad haar uitvoerend bestuur. (Applaus). De Volkenbond dient slappen te doen om den aanmaak van munitie en wapentuig door particulieren onmogelijk te maken. Ook moet het gebruik van giftige gassen, onderzeeboonz. door dit lichaam worden verboden. Het systeem der mandaten wil spr. voor ziel; wel gehandhaaJvi zien. m de mandaten door den Volkimbond ook kunnen woeden ingetrokken, indien de maiidaatniogecdh<ia zich het vertrouwen in haar gesteld niet waardig heeft getoond. Kusland moet weer in de gemeenschap der naties worden opgenomen en [sering volledig erkend. In dit congt r. een aanvang van <en :. unenwerken der drie internationale gemeenschappen van co\\xf6peratieve ve;. -:. vakbonden en arbeidersorganisaties, la afwachting hiervan roept spr. uit. \\u201eLeve de Internationale!\" (Laadnrtg applaus). Hierna ging het rongres tot halfdrie uiteen. In den namiddag was het woord aan den S2-jarig\\' n hoo.-leeraar aan de Sorbonne. Pro- K. Bnisson. HU hield een referaat over het onderwerp: \\u201eDe inrichtingen van onderwijs en opvoeding als middel van pro\\u25a0la van de pacifistische 1 . Spr. betoogde de noodzakelijkheid van ern radicale hervorming van de men-: de verschillende lagen der bevolking, opdat een krachtige actie voor de ontwapening en ter bestrijdin van der, oorlog mogelijk worde. In he; - .irderd in een voor den oorlog gunstigen zin door de plastische en grafische kunst en door het onderwijs, dat de vereering van de oorlogsheiden stelt boven die van de denkers, uitvinders en andere mannen van wetenschap. Spr. deed een beroep op alle opvoeders. \\u2022lijken, kunstenaars, journalisten en litteratoren en meer in het bijzonder op hunne organisaties om middelen te beramen ten einde do wereld de verschrikkingen van den oorlog en de ~ij t 0 ,en. Te dien einde beveelt spr het congres de volgende middelei aan: a. de radicale hervorming van het ornler:i het algemeen, maar vooral van 1 schiedenis in dien zin, dat daarin meer aandacht wordt geschonken aan de chavisg, de namen en de iri\\xbb-*\\xbbr.n der gnioie denkers, het werk van uit\\xbb en dat alles vermeden worde, wal dient tot verheerlijking van de oorlogshel\\xbb\". b. ri. ran de pin. grafische kunst aan de paci: door nlandbeelden 01 -n van per. i.aak var, den vrede of den werkeiijken vooruitgang van de menschheid hebben gediend; c. het gebruik van de school- en \\u2022 pen met het doel ien oe aandacht van de m op de wreedheden van den oorlog en zijn r.uiipzalice \\xaboor de tegenwoordige en toekom. generaties. el congrrs dient er alle mannen m vron\\u25a0 \\u25a0:-, ir, liet bijzonder alle hoofdarbeiders sporen, al hunne talenter, in van de groote zaak der Inter n.ile eenheid, opdat de ii-.-m-e-hheid \\u25a0 tui duurzaaiun en a_g -aioeoen vrede.Daartoe dient het congres alle tnte\\xdfectuee UOOdigen tot de vorming va. i. welke de noodige maat spr. uitt\\'. propaganda, nemen kan. In .. ri. spr. een resolutie in. \"\\' M\\xfcnchen, die niet aanwezig was. sprak na professor Buisson. de heer H. von Gerlach van de Deutsche Liga f\\xfcr Menschenrechte Bt r de pacifistische organisaties en haar rol in de internationale beweging tegen dea oorlog.onderwerp, dat de heer Von Gerlarh besprak, wa.- hetzelfde als prof. Quid.i. Bullen behandelen. Men vindt hun beider standpunt geresumeerd in de volgende hi\\xfce, die de heer Quidde aan het congres had \\u2022Voorgelegd: \\u201eHet Internationale Vredescongres, oordeelend, dat tot op den huldigen dag de \"pacifistische propaganda meer op theoretisch dan op pra\\xabisch terrein is gevoerd; overtuigd, dat de deelneming van de arbei-der organisaties in aanzienlijker mate dan in het verleden, de uitvoering zal mogelijk maken van maatregelen-van-practischen-aard tegen den oorlog,beveelt de samenwerking \\xbb\\xbbri Tan alle kreet\" .iren den oorlog en v\\xf3\\xf3r den vrede willen werken.In het belang van Aeze samenwerking, acht het congres het noodzakelijk, dat alle satlee, die in het belang van den vrede saam zijn. elkander vaker ontmoeten, met het doel, den stand van de pacifistische bc* na te gaan, zich een helder inzicht te vormen omtrent de internationale politiek en krachtdadig in t\\xbb grijpen. Zonrira een oorlog breken, of wanneer tich internat, corr.p\\xfcca\\xfces voordoer.. die de b> I \\u2022\\u2022 TT\\xbbl>vre*i in gevaar zouder nen brengen. (Geroep: Dan is het te laai Ten einde dr venrpreide krachten te centraliaeeren. is het gewenscht een goed g\"r\\xbbr--: erd bure.\" I ehten. onafhar: van alle r- en onderb I .eiflstische organisahaar volledige onafhankelijkheid md comifv van het bureau zal op vaste tijdstippen b - en steeds, wanneer d- behoefte daartoe - einde alle no\\xbb rnaatrezirr. tr nemen om een permanente pacifi\\' paganda te vc ich voegde in zijn mondelinge toelK \\u25a0 dat hij zach dit bureau z\\xf3\\xf3 denkt, dat daarbij zullen zijn aangesloten. I.V.V. en van groote Internationale organisat;. soogen voorwat be; etrtjding van den oorlog, voorts het Internationaal Vredasbureau tp Bern. de Volkenbondsveree llrussel. de I.igue -pour la Drorit de 1\\' Homme en andere organisaties. Het congTes werd hierna verdaagd tot morgen. Dan komt de heer Fhnmen aan het woord, en na hem beginnen de algemeene discussies. De voorzitter deelde mede. dat elk s; twfartri erhrn hoek v-erd tegen kring noga! geprotesteerd, doch zonder sucrrjv Te half vijf ging tet congres uiteen.', u'year': u'1922', u'title': u'HET INT. VREDESCONGRES. ONDERWIJS ALS PROPAGANDA. SAMENWERKING BEPLEIT.'}, u'_index': u'telegraaf'}], u'total': 4, u'max_score': 2.9305606}, u'_shards': {u'successful': 5, u'failed': 0, u'total': 5}, u'took': 90, u'timed_out': False}\n"
     ]
    }
   ],
   "source": [
    "res = search(query, advanced=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result page function\n",
    "\n",
    "* Take query output and use score to order result on a Search Engine Result Page (SERP).\n",
    "* Return title, link, and description of each hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "* Manual relevance check\n",
    "* P@10\n",
    "* Change the ranking of the system + explain what is going on and why it is improving/decreasing\n",
    "\n",
    "Evaluate your results Let 2 persons assess the relevancy of the top 10 documents for 5 different queries. Compute Cohen's kappa. Determine the average precision at 10 for your system based on these 10 queries, and the two relevance assesments. Also plot the P@10 (for both judges) for each query, showing differences in hard and easy queries. Describe clearly how you solved differences in judgements. \n",
    "So, both provide the actual query, and a description of the information need that was behind the query.\n",
    "Give a small set of clear guidelines for judging the results, and let your judges follow these guidelines.\n",
    "It is far more interesting to have difficult queries (both for the search engine and for the judges) than to have queries on which all ten retrieved documents are relevant. So, try to create a good list of information needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
