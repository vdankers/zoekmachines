{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telegraaf Search Engine - Elastic Search assignment\n",
    "\n",
    "### Notebook made by\n",
    "\n",
    "__Name(s)__: Adriaan de Vries, Max Briel, Verna Dankers\n",
    "\n",
    "__Student id(s)__ : 10795227, 10606513, 10761225\n",
    "\n",
    "### Pledge (taken from [Coursera's Honor Code](https://www.coursera.org/about/terms/honorcode) )\n",
    "\n",
    "Put here a selfie with your photo where you hold a signed paper with the following text: (if this is team work, put two selfies here). The link must be to some place on the web, not to a local file. **Assignments without the selfies will not be graded and receive 0 points.**\n",
    "\n",
    "> My answers to homework, quizzes and exams will be my own work (except for assignments that explicitly permit collaboration).\n",
    "\n",
    ">I will not make solutions to homework, quizzes or exams available to anyone else. This includes both solutions written by me, as well as any official solutions provided by the course staff.\n",
    "\n",
    ">I will not engage in any other activities that will dishonestly improve my results or dishonestly improve/hurt the results of others.\n",
    "\n",
    "<img width=30% src=\"http://i63.tinypic.com/2itj1ic.jpg\" border=\"0\">\n",
    "<img width=30% src='http://oi63.tinypic.com/2q3srh3.jpg'/>\n",
    "<img width=30% src='http://i67.tinypic.com/2hd1is5.jpg'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Abstract\n",
    "\n",
    "In this notebook we have created a search engine using ElasticSearch. We have indexed articles from the newspaper Telegraaf, from http://data.politicalmashup.nl/arjan/telegraaf/, 12 GB of data. After those articles have been indexed, the search engine is ready to use. The engine allows you to do both simple search, with plain text queries, and advanced search where you can also select values for facets. \n",
    "Apart from the normal search engine we also created a tool for evaluating the engine with multiple judges.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Assignment\n",
    "\n",
    "The assignment gave us some guidelines about what the search engine should be able to do. Based on these points we seperated the process in four stages. Instead of creating a wiki about these points, we explained every step here in this notebook.\n",
    "\n",
    "#### Stage 1: Populating the database\n",
    "* Reading XML and converting it to JSON\n",
    "* Indexing with bulk commands\n",
    "\n",
    "#### Stage 2: Search\n",
    "* Simple search. Show links to documents and some description\n",
    "* Advanced search. Let a user be able to search in several fields, let the user search in both title and tekst fields.\n",
    "\n",
    "#### Stage 3: Present results\n",
    "* Give a result page (SERP), with links to the documents and some description of each hit.\n",
    "* Represent the hits of a query with a wordcloud of 25-50 informative words. The wordcloud should somehow summarise what the collection has to say about the query. You may think of these words as words that you could add to the query in order to improve recall (blind relevance feedback/query expansion).\n",
    "* Give next to a traditional list of results, a timeline in which you indicate how many hits there are over time.\n",
    "* Show how many hits there are for each 'dc:subject' value.\n",
    "\n",
    "#### Stage 4: Evaluation\n",
    "* Evaluate your results Let 2 persons assess the relevancy of the top 10 documents for 5 different queries. Compute Cohen's kappa. Determine the average precision at 10 for your system based on these 10 queries, and the two relevance assesments. Also plot the P@10 (for both judges) for each query, showing differences in hard and easy queries. Describe clearly how you solved differences in judgements. \n",
    "* Change the ranking of your system, compute the average precision at 10 using your 10 queries, compare the results to your old system, and EXPLAIN what is going on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Search Engine\n",
    "\n",
    "Before running ES run: \n",
    "\n",
    "    export ES_HEAP_SIZE=Half_RAM\n",
    "\n",
    "where Half_RAM is half your ram\n",
    "\n",
    "AND: \n",
    "in /config/elasticsaerch.yml add \n",
    "\n",
    "    indices.memory.index_buffer_size: 50% \n",
    "    threadpool.bulk.queue_size: 1000\n",
    "    index.store.type: mmapfs\n",
    "\n",
    "To start the Elastic searh serive, please run the following code in commandline:\n",
    "\n",
    "    ./elasticsearch-2.4.1/bin/elasticsearch --node.name telegraaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate connection to the Elastic Search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You Know, for Search\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "\n",
    "HOST = 'http://localhost:9200/'\n",
    "es = Elasticsearch(hosts=[HOST],retry_on_timeout=True)\n",
    "\n",
    "# Check if connection has been made\n",
    "print es.info()['tagline']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1: Populate ES database\n",
    "\n",
    "### Generator to read Telegraaf XML and add them to the ES database\n",
    "\n",
    "A generator 'reads' the XML files and put them into the ES database without storing them into memory. \n",
    "\n",
    "The XML file is read as a stream and while reading the file the required informatio per document is extracted.Once one document has been filled the document is yielded, because we're using a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "from os import listdir\n",
    "from os.path import isfile\n",
    "import xml.etree.ElementTree as etree\n",
    "from lxml import etree\n",
    "\n",
    "def read(year):\n",
    "    \"\"\"\n",
    "    Return a generator for the date, subject(type), \n",
    "    title, and text for each item in the given year. \n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    date = ''\n",
    "    subject =''\n",
    "    identifier = ''\n",
    "    text = ''\n",
    "    title = ''\n",
    "    for event, elem in etree.iterparse(year,events=(\"start\", \"end\")):\n",
    "        if event =='end':\n",
    "            if elem.tag == '{http://purl.org/dc/elements/1.1/}date':\n",
    "                date = elem.text\n",
    "                elem.clear()\n",
    "            elif elem.tag == '{http://purl.org/dc/elements/1.1/}subject':\n",
    "                subject = elem.text\n",
    "                elem.clear()\n",
    "            elif elem.tag == '{http://purl.org/dc/elements/1.1/}identifier':\n",
    "                identifier = elem.text\n",
    "                elem.clear()\n",
    "            elif elem.tag == 'title':\n",
    "                if elem.text == None:\n",
    "                    title = ''\n",
    "                else:\n",
    "                    title = elem.text\n",
    "                elem.clear()\n",
    "            elif elem.tag == 'p':\n",
    "                if elem.text == None:\n",
    "                    text = ''\n",
    "                else:\n",
    "                    text = elem.text\n",
    "                elem.clear()\n",
    "            elif elem.tag == '{http://www.politicalmashup.nl}root':\n",
    "                elem.clear()\n",
    "                yield (date,subject,identifier,title,text)\n",
    "            else:\n",
    "                elem.clear()\n",
    "\n",
    "documents = ['./Telegraaf/'+i for i in listdir('./Telegraaf') if not isfile(i)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Telegraaf Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "health status index     pri rep docs.count docs.deleted store.size pri.store.size \r\n",
      "yellow open   telegraaf   5   1    5655966            0     10.8gb         10.8gb \r\n",
      "yellow open   megacorp    5   1          0            0       800b           800b \r\n"
     ]
    }
   ],
   "source": [
    "# List of all indices\n",
    "! curl 'localhost:9200/_cat/indices?v'\n",
    "\n",
    "# Create the telegraaf index in our telegraaf node\n",
    "es.indices.create(index='telegraaf', ignore=400)\n",
    "\n",
    "# turn refresh to a less frequent rate to speed up bulk import\n",
    "es.indices.put_settings(index='telegraaf',body={\"index\" : \n",
    "                                            {\"refresh_interval\" : \"30s\"\n",
    "                                            }\n",
    "                                       })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index Telegraaf documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting time: 1477420650.39\n",
      "Document: ./Telegraaf/telegraaf-1971.xml\n",
      "[Done] 97.113476038\n",
      "Succesful injections:  174873\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1979.xml\n",
      "[Done] 97.8079650402\n",
      "Succesful injections:  149075\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1974.xml\n",
      "[Done] 93.9970080853\n",
      "Succesful injections:  137155\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1994.xml\n",
      "[Done] 150.787832022\n",
      "Succesful injections:  251526\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1990.xml\n",
      "[Done] 138.377987146\n",
      "Succesful injections:  228202\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1981.xml\n",
      "[Done] 124.811862946\n",
      "Succesful injections:  203119\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1963.xml\n",
      "[Done] 81.1194469929\n",
      "Succesful injections:  120901\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1976.xml\n",
      "[Done] 129.643987179\n",
      "Succesful injections:  179814\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1989.xml\n",
      "[Done] 157.363436937\n",
      "Succesful injections:  230444\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1962.xml\n",
      "[Done] 139.618813992\n",
      "Succesful injections:  180677\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1973.xml\n",
      "[Done] 115.262254\n",
      "Succesful injections:  117418\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1985.xml\n",
      "[Done] 177.812840939\n",
      "Succesful injections:  173750\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1992.xml\n",
      "[Done] 130.971071005\n",
      "Succesful injections:  193719\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1966.xml\n",
      "[Done] 113.816015959\n",
      "Succesful injections:  144359\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1988.xml\n",
      "[Done] 37.0302460194\n",
      "Succesful injections:  62618\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1970.xml\n",
      "[Done] 220.756904125\n",
      "Succesful injections:  238958\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1993.xml\n",
      "[Done] 161.174058914\n",
      "Succesful injections:  265515\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1923.xml\n",
      "[Done] 0.206234931946\n",
      "Succesful injections:  228\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1978.xml\n",
      "[Done] 193.86420083\n",
      "Succesful injections:  211211\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1983.xml\n",
      "[Done] 142.792152882\n",
      "Succesful injections:  135899\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1961.xml\n",
      "[Done] 99.2728590965\n",
      "Succesful injections:  106988\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1965.xml\n",
      "[Done] 49.7844350338\n",
      "Succesful injections:  46140\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1918.xml\n",
      "[Done] 10.4150841236\n",
      "Succesful injections:  6263\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1982.xml\n",
      "[Done] 203.53243804\n",
      "Succesful injections:  170929\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1984.xml\n",
      "[Done] 160.43089509\n",
      "Succesful injections:  174923\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1975.xml\n",
      "[Done] 227.07770896\n",
      "Succesful injections:  202926\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1987.xml\n",
      "[Done] 334.698056936\n",
      "Succesful injections:  271758\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1972.xml\n",
      "[Done] 222.377041101\n",
      "Succesful injections:  203708\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1968.xml\n",
      "[Done] 134.227461815\n",
      "Succesful injections:  154713\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1986.xml\n",
      "[Done] 170.369179964\n",
      "Succesful injections:  157296\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1951.xml\n",
      "[Done] 33.0668420792\n",
      "Succesful injections:  37375\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1980.xml\n",
      "[Done] 148.400204897\n",
      "Succesful injections:  142228\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1969.xml\n",
      "[Done] 196.722019911\n",
      "Succesful injections:  184627\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1922.xml\n",
      "[Done] 6.94085502625\n",
      "Succesful injections:  6692\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1991.xml\n",
      "[Done] 152.802206993\n",
      "Succesful injections:  156259\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Document: ./Telegraaf/telegraaf-1977.xml\n",
      "[Done] 272.449551105\n",
      "Succesful injections:  233680\n",
      "Failed injections: 0\n",
      "\n",
      "\n",
      "Finished 4927.18455219\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#Import the information into the database\n",
    "def bulk_per_doc(documents):\n",
    "    \"\"\"\n",
    "    Populate your database by indexing all files from a given \n",
    "    list of documents, using bulk operations.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    print \"Starting time:\", start\n",
    "    for doc in documents:\n",
    "        print \"Document:\", doc\n",
    "        failed = 0\n",
    "        succes = 0\n",
    "        start_doc = time.time()\n",
    "        k = ({'_index':'telegraaf', '_type':subject, '_id':identifier, \n",
    "              '_source':{'year':date[:4], 'date':date[5:], 'title':title, \n",
    "                         'text':text}} for (date,subject,identifier,title,text) in read(doc))\n",
    "        for (ok, res) in helpers.parallel_bulk(es,k, chunk_size=4000,\n",
    "                                               max_chunk_bytes=15728640, request_timeout=10000):\n",
    "            if not ok:\n",
    "                failed +=1\n",
    "            else:\n",
    "                succes += 1\n",
    "        end_doc = time.time()\n",
    "        print '[Done]', end_doc-start_doc\n",
    "        print \"Succesful injections: \", succes\n",
    "        print \"Failed injections:\", failed\n",
    "        print '\\n'\n",
    "    end =time.time()\n",
    "    print \"Finished\", (end_doc-start)\n",
    "\n",
    "bulk_per_doc(documents)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'acknowledged': True}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the refresh rate back to default\n",
    "es.indices.put_settings(index='telegraaf',body={\"index\" : \n",
    "                                            {\"refresh_interval\" : \"1s\"\n",
    "                                            }\n",
    "                                       })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2: The Search System\n",
    "\n",
    "For both simple and advanced search we need a well formulated Elastic Search query with which we can ask our Telegraaf index for results. \n",
    "\n",
    "For the simple search we ask for documents that match the query terms, for both title and text.\n",
    "For the advanced search we ask for documents that match the query terms. Those documents are than filtered by the facet values the user entered: the documents must be from the range of years that was selected, and from the subjects that were entered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter_path can help reduce the amount of data that is returned by the es.search\n",
    "# The query context is for how well the document fits the query\n",
    "# The filter context is a boolean context. Does it match or not.\n",
    "# example: Does this timestamp fall into the range 2015 to 2016?\n",
    "# In other words, all terms must be present in at least one field for a document to match.\n",
    "\n",
    "def search(query, advanced=False):\n",
    "    \"\"\"\n",
    "    Given a query it returns the results from an ElasticSearch query\n",
    "    \"\"\"\n",
    "    if advanced:\n",
    "    \n",
    "        must = []\n",
    "                \n",
    "        if query[0]:\n",
    "            must = [{\"type\": {\"value\": i}} for i in query[0]]\n",
    "        # Advanced search query\n",
    "        q = {\"query\": \n",
    "                {\"filtered\": \n",
    "                    {\"query\": {\n",
    "                        \"multi_match\": \n",
    "                            {\"query\" : query[1],\n",
    "                             \"type\" : \"cross_fields\",  # with 'and' operator this is strict\n",
    "                             \"fields\" : query[2],\n",
    "                             \"operator\" : 'and'\n",
    "                            }\n",
    "                        },\n",
    "                     \"filter\": \n",
    "                        {'and':\n",
    "                            [{\"range\":\n",
    "                                {\"year\":\n",
    "                                    {\"gte\":query[3][0],\n",
    "                                     \"lte\":query[3][1]\n",
    "                                    }\n",
    "                                }\n",
    "                              },\n",
    "                             {\"bool\":\n",
    "                                 {\"should\":must\n",
    "                                 }\n",
    "                             }\n",
    "                              ]\n",
    "                         }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "    else:  \n",
    "        # Simple search\n",
    "        q = {'query':\n",
    "                {'multi_match':\n",
    "                    {'query' : query,\n",
    "                     'type' : 'cross_fields',  # with 'and' operator \n",
    "                     'fields' : ['title', 'text'],\n",
    "                     'operator' : 'and'\n",
    "                     }\n",
    "                 }\n",
    "             }\n",
    "    res = es.search(index='telegraaf', size=50, body=q)\n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3: Present the results\n",
    "\n",
    "## Result page function\n",
    "\n",
    "* Give a result page (SERP), with links to the documents and some description of each hit.\n",
    "* Represent the hits of a query with a wordcloud of 25-50 informative words. The wordcloud should somehow summarise what the collection has to say about the query. You may think of these words as words that you could add to the query in order to improve recall (blind relevance feedback/query expansion).\n",
    "* Give next to a traditional list of results, a timeline in which you indicate how many hits there are over time.\n",
    "* Show how many hits there are for each 'dc:subject' value.\n",
    "\n",
    "#### SERP\n",
    "Our SERP shows the title of an article, which is a link to the webpage where the article can be viewed, and a description of 15 words. The query terms are highlighted in this description, if they are present. The documents are ranked according to their score. If the user chose to do advanced search, a timeline or wordcloud can be displayed.\n",
    "After the user entered a query and his values for the facets, the number of hits per subject are shown at the top of the page, like this: 'advertentie (10348)'.\n",
    "\n",
    "#### Worcloud\n",
    "Since stopwords have high frequencies, they are likely to occupy most places in the word cloud. We therefore remove a list of common Dutch stop words. Only single words (unigrams) are included in the cloud and stemming is applied. To create a word cloud all terms from the search results are sorted by their probabilities and a fixed number of the top ranked terms are kept.\n",
    "\n",
    "#### Timeline\n",
    "The timeline displays the number of returned search results distributed over the years. If the returned result set only contains documents from one year, the timeline will be created for months of that year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Determine values for the year facets\n",
    "agg={\n",
    "    \"aggs\" : {\n",
    "        \"_source\" : {\n",
    "            \"terms\" : { \"field\" : \"year\", \"size\" : len(documents) }\n",
    "            \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "agg2={\n",
    "    \"aggs\" : {\n",
    "        \"_type\" : {\n",
    "            \"terms\" : { \"field\" : \"_type\" }\n",
    "            \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Get field values for the year\n",
    "res = es.search(index='telegraaf', body=agg)\n",
    "unique_years_string = sorted([ \"%s (%d documents)\" % (item['key'], item['doc_count']) \n",
    "                      for item in res['aggregations']['_source']['buckets']])\n",
    "unique_years = sorted([item['key'] for item in res['aggregations']['_source']['buckets']])\n",
    "\n",
    "# Get field values for document type\n",
    "res = es.search(index='telegraaf', body=agg2)\n",
    "unique_doc_types_string = [ \"%s (%d documents)\" % (item['key'], item['doc_count']) \n",
    "                            for item in res['aggregations']['_type']['buckets']]\n",
    "unique_doc_types = [item['key'] for item in res['aggregations']['_type']['buckets']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MaxNLocator\n",
    "from stop_words import get_stop_words\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import snowballstemmer\n",
    "\n",
    "COLOUR = 'Crimson'\n",
    "\n",
    "def position_sentences(positions, text, m):\n",
    "    \"\"\"\n",
    "    Return a sentence in which multiple m words \n",
    "    from the text occur, based on a list of positions.\n",
    "    \"\"\"\n",
    "    mini = positions[0]\n",
    "    maxi = mini\n",
    "    for i in positions[1:]:\n",
    "        if i > mini and i <= mini + m:\n",
    "            maxi = i\n",
    "    diff = int(math.floor((m - (maxi - mini)) / 2))\n",
    "    return '...'+' '.join(text[mini-diff:maxi+diff])+'...'\n",
    "\n",
    "\n",
    "def extract_description(query, text, m):\n",
    "    \"\"\"\n",
    "    Given a query, select m words from the text that\n",
    "    contain words from the query.\n",
    "    \"\"\"\n",
    "    query = query.split()\n",
    "    stext = text.split(' ')\n",
    "    positions = []\n",
    "    # get the word position \n",
    "    for word in query: \n",
    "        for i,term in enumerate(stext):\n",
    "            if word in term:\n",
    "                positions.append(i)\n",
    "                \n",
    "    for i, word in enumerate(stext):\n",
    "        if i in positions:\n",
    "            stext[i] = '<b>' + word + '</b>'\n",
    "        else:\n",
    "            stext[i] = word            \n",
    "    \n",
    "    positions = [i for i in sorted(positions) if i > 7]\n",
    "\n",
    "    # If word(s) appeared in text, return these sentences\n",
    "    if positions:\n",
    "        description = position_sentences(positions, stext, m)\n",
    "    # If the word only occured in title, return first sentence/part of first sentence\n",
    "    else:\n",
    "        description = ' '.join(stext[:15]) + '...'\n",
    "    return description\n",
    "\n",
    "\n",
    "def result_page(query, total_hits, hits):\n",
    "    \"\"\"\n",
    "    Given a query and its hits, return what information\n",
    "    to output to the user in a SERP.\n",
    "    \"\"\"\n",
    "    total = widgets.HTML('Total hits: '+str(total_hits)+\" Shown: 10\")\n",
    "    results = []\n",
    "    descriptions = []\n",
    "    for elem in hits:\n",
    "        if elem['_source']['title'] == '':\n",
    "            results.append(widgets.HTML('<h3><a href=\"http://kranten.kb.nl/view/article/id/'+ \n",
    "                                        str(elem['_id'])+'\" target=\"_blank\">No Title Available</a></h3>'))\n",
    "        else:\n",
    "            results.append(widgets.HTML(value = '<h3><a href=\"http://kranten.kb.nl/view/article/id/'+ \n",
    "                                        str(elem['_id'])+'\" target=\"_blank\">'+elem['_source']['title']+'</a></h3>'))\n",
    "        results.append(widgets.HTML(extract_description(query, elem['_source']['text'],15)))\n",
    "        # Uncomment following line if you want to display the scores\n",
    "        #results.append(widgets.HTML(\"Score: \" + str(elem['_score'])))\n",
    "    return results\n",
    "    \n",
    "def create_timeline(years, dates):\n",
    "    \"\"\"\n",
    "    Display the years or dates from the hits\n",
    "    on a timeline.\n",
    "    \"\"\"\n",
    "\n",
    "    ax = plt.figure(figsize=(15,4)).gca()\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    \n",
    "    if len(set(years)) == 1:\n",
    "        xlabel = \"Months of the year \" + str(years[0])\n",
    "        bins = [ int(date[:2]) for date in dates ]\n",
    "        #counted = Counter(months)\n",
    "        names = ['           Januari','             Februari','         Maart',\n",
    "                 '        April', '        Mei','        Juni','        Juli',\n",
    "                 '               Augustus','                 September',\n",
    "                 '               Oktober','                November',\n",
    "                 '                December']\n",
    "        xlim = [1,13]\n",
    "        plt.xticks(range(1,13),names)\n",
    "        bin_range = range(1,13)\n",
    "    else: \n",
    "        bins = years \n",
    "        bin_range = range(min(years),max(years)+1)\n",
    "        xlabel = \"Years\"\n",
    "        xlim = [min(years),max(years)]\n",
    "                               \n",
    "    ax.set_xlim(xlim)\n",
    "    \n",
    "    # Mooi roze is niet leelijk\n",
    "    plt.hist(bins, bins=bin_range, color=COLOUR)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"Number of documents\")\n",
    "    plt.show()\n",
    "    \n",
    "def create_wordcloud(text, n):\n",
    "    \"\"\"\n",
    "    Display a wordcloud with at most n words, generated\n",
    "    from the given text.\n",
    "    \"\"\"\n",
    "    # Filter words to use for the wordcloud, by stemming and stop words removal\n",
    "    stop_words = get_stop_words(\"dutch\")\n",
    "    stemmer = snowballstemmer.stemmer(\"dutch\")\n",
    "    text = [word for word in text if word.lower() not in stop_words]\n",
    "    text = stemmer.stemWords(text)\n",
    "\n",
    "    # Plot wordcloud\n",
    "    wordcloud = WordCloud(background_color=\"white\", max_words = n).generate(\" \".join(text))\n",
    "    plt.figure()    \n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "from IPython.display import display, clear_output\n",
    "from IPython.core.display import HTML\n",
    "from ipywidgets import widgets, interact, Layout\n",
    "\n",
    "RES = []\n",
    "\n",
    "def get_count(ty, query, fields,time):\n",
    "    \"\"\"Get the count of a type, query, fields, and time.\"\"\"\n",
    "    \n",
    "    return es.count(index='telegraaf',\n",
    "                    body={'query':{\"filtered\":{\"query\":\n",
    "                                                  {\"multi_match\": \n",
    "                                                      {\"query\" : query,\n",
    "                                                          \"type\" : \"cross_fields\",  \n",
    "                                                          \"fields\" : fields,\n",
    "                                                          \"operator\" : 'and'\n",
    "                                                       }\n",
    "                                                  },\n",
    "                                                  \"filter\":\n",
    "                                                      {\"bool\":\n",
    "                                                           {\"must\": \n",
    "                                                               [{\"term\": {\"_type\": ty}},\n",
    "                                                                {\"range\":{\"year\":{\n",
    "                                                                   \"gte\":time[0],\n",
    "                                                                   \"lte\":time[1]}}}]\n",
    "                                                            }\n",
    "                                                      }\n",
    "                                              }\n",
    "                                    }\n",
    "                         })['count']\n",
    "\n",
    "\n",
    "# Initialise SERP such that on the first the system doesn't return an error\n",
    "SERP = ''\n",
    "\n",
    "# SEARCH FIELD AND BUTTON\n",
    "text = widgets.Text(placeholder='Vul een zoekterm in')\n",
    "search_button = widgets.Button(description=\"Search\")\n",
    "\n",
    "# ADVANCED SEARCH TOGGLE BUTTON\n",
    "advanced = widgets.ToggleButton(description=\"Toggle Advanced Search\", layout=Layout(background_color=COLOUR),\n",
    "                                width='220px', button_style='info', value=True)\n",
    "\n",
    "\n",
    "# INITIAL SEARCHBAR CONTAINER\n",
    "container = widgets.HBox((widgets.HTML('',width='130px'),\n",
    "                          widgets.HTML('Zoektermen:'),\n",
    "                          text, \n",
    "                          widgets.HTML(''), \n",
    "                          search_button,\n",
    "                          widgets.HTML('',width='50px'),\n",
    "                          advanced))\n",
    "container.layout.align_items='center'\n",
    "\n",
    "#===================================================================\n",
    "#                   TEXT FIELDS: CHECKBOXES\n",
    "#===================================================================\n",
    "\n",
    "# TEXT FIELD CHECKBOX\n",
    "text_check = widgets.Checkbox(value=True, width='50px')\n",
    "textfield = widgets.HBox(children=(widgets.HTML('',width='20px'),\n",
    "                                   widgets.HTML('Text'),\n",
    "                                   text_check))\n",
    "textfield.layout.align_items='center'\n",
    "\n",
    "# TITLE FIELD CHECKBOX\n",
    "title_check = widgets.Checkbox(value=True, width='50px')\n",
    "titlefield = widgets.HBox(children=(widgets.HTML('',width='20px'),\n",
    "                                    widgets.HTML('Title'),\n",
    "                                    title_check))\n",
    "titlefield.layout.align_items='center'\n",
    "\n",
    "# FINAL CONTAINER\n",
    "c_textfields = widgets.VBox(children=(widgets.HTML('Welke zoekvelden?'),\n",
    "                                      textfield, \n",
    "                                      titlefield))\n",
    "titlefield.layout.align_items='center'\n",
    "\n",
    "#==============================================================\n",
    "#        DOCUMENT TYPES: CHECKBOXES - TEXT VALUES\n",
    "#==============================================================\n",
    "\n",
    "# this should probably be rewritten to not include a class. It's overkill \n",
    "# Just setting them as a ??_text should be suficient. \n",
    "class doc_widget:\n",
    "    \n",
    "    def __init__(self,name,value):\n",
    "        self.value = value\n",
    "        self.name = name\n",
    "        self.widget = widgets.Text(str(self.name)+' ('+str(self.value)+')', \n",
    "                                   width='220px', disabled=True) \n",
    "        # Disable=True to make sure the user can't change the value\n",
    "        \n",
    "    def set_value(self, value):\n",
    "        self.value = value\n",
    "        self.widget = widgets.Text(str(self.name)+' ('+str(self.value)+')', \n",
    "                                   width='220px', disabled=True)\n",
    "        # Disable=True to make sure the user can't change the value\n",
    "        \n",
    "# THE TEXT VALUES\n",
    "doc_types = {}\n",
    "for i in unique_doc_types:\n",
    "    doc_types[i]  = doc_widget(i,0)\n",
    "\n",
    "# CHECKBOXES\n",
    "ad_check = widgets.Checkbox(value=True, width='20px')\n",
    "ar_check = widgets.Checkbox(value=True, width='20px')\n",
    "io_check = widgets.Checkbox(value=True, width='20px')\n",
    "fb_check = widgets.Checkbox(value=True, width='20px')\n",
    "\n",
    "# FIRST ROW\n",
    "row1 = widgets.HBox(children=(ad_check,\n",
    "                              doc_types['advertentie'].widget, \n",
    "                              widgets.HTML('',width='20px'),\n",
    "                              ar_check,\n",
    "                              doc_types['artikel'].widget))\n",
    "row1.layout.align_items='center'\n",
    "\n",
    "# SECOND ROW\n",
    "row2 = widgets.HBox(children=(io_check,\n",
    "                              doc_types['illustratie met onderschrift'].widget,\n",
    "                              widgets.HTML('',width='20px'),\n",
    "                              fb_check,\n",
    "                              doc_types['familiebericht'].widget))\n",
    "row2.layout.align_items='center'\n",
    "\n",
    "# FINAL CONTAINER \n",
    "c_types = widgets.VBox(children=(widgets.HTML('Welke type documenten?'),\n",
    "                                 row1,\n",
    "                                 row2))\n",
    "\n",
    "#================================================================================== \n",
    "#                  TIME PERIOD SLIDER - TIMELINE - WORDCLOUD\n",
    "#==================================================================================\n",
    "\n",
    "# TIME PERIOD SLIDER\n",
    "years = widgets.IntRangeSlider(value=[int(unique_years[0]), int(unique_years[-1])], \n",
    "                               min=int(unique_years[0]),\n",
    "                               max= int(unique_years[-1]), \n",
    "                               step=1)\n",
    "\n",
    "# TIMELINE  - WORDCLOUD \n",
    "timeline_check = widgets.Checkbox(value=False, width='50px')\n",
    "wordcloud_check = widgets.Checkbox(value=False, width='50px')\n",
    "c_extra_options = widgets.HBox(children=(widgets.HTML(\"Tijdlijn\"),\n",
    "                                         timeline_check, \n",
    "                                         widgets.HTML(\"Wordcloud\"), \n",
    "                                         wordcloud_check))\n",
    "c_extra_options.layout.align_items = 'center'\n",
    "c_extra_options.layout.justify_content = 'center'\n",
    "\n",
    "# FINAL CONTAINER\n",
    "c_slide = widgets.VBox(children=(widgets.HTML(\"Kies tijdsperiode:\"), \n",
    "                                 years,\n",
    "                                 c_extra_options\n",
    "                                ))\n",
    "#===================================================================== \n",
    "\n",
    "# Advanced settings container\n",
    "container_adv = widgets.HBox((c_textfields,   \n",
    "                              c_types,       \n",
    "                              c_slide), )    \n",
    "container_adv.layout.justify_content = 'space-around'\n",
    "container_adv.visible=True\n",
    "\n",
    "#===================================================================== \n",
    "\n",
    "def advanced_options(sender):\n",
    "    if sender['new'] == True:\n",
    "        container_adv.visible = True\n",
    "        # Show the advanced settings\n",
    "        \n",
    "    elif sender['new'] == False:\n",
    "        container_adv.visible = False\n",
    "        # Hide the advanced settings\n",
    "\n",
    "def show_timeline(sender):\n",
    "    #res = RES\n",
    "    if sender['new']==True:\n",
    "        if timeline_check.value: \n",
    "            timeline_years = [hit['_source']['year'] for hit in res['hits']['hits']]\n",
    "            dates = [hit['_source']['date'] for hit in res['hits']['hits']]   \n",
    "            if timeline_years != []:\n",
    "                create_timeline(timeline_years, dates)\n",
    "    elif sender['new']==False:\n",
    "        clear_output()\n",
    "        \n",
    "#=====================================================================        \n",
    "\n",
    "def handle_submit(sender):\n",
    "    \"\"\"\n",
    "    This function handles the search after the button has been \n",
    "    pressed or the search field has been submitted\n",
    "    \"\"\"\n",
    "    # Define SERP as a global variable, such that for the first \n",
    "    # loop it doesn't try to close the non-existing SERP\n",
    "    global SERP \n",
    "    if SERP != '':\n",
    "        SERP.close()\n",
    "    clear_output()\n",
    "    \n",
    "    # SIMPLE SEARCH\n",
    "    if container_adv.visible == False:\n",
    "        display('Zoeken..')\n",
    "        res = search(text.value)\n",
    "        clear_output()\n",
    "        results = result_page(text.value, res['hits']['total'], res['hits']['hits'])\n",
    "        if results == []:\n",
    "            SERP = widgets.VBox(children=(widgets.HTML('', height='20px'),\n",
    "                                          widgets.HTML(\"<center>Geen zoekresultaten \\\n",
    "                                          zijn gevonden. Probeer het opnieuw</center>\")))\n",
    "        else:            \n",
    "            pages = []\n",
    "            page = []\n",
    "            for i, result in enumerate(results):\n",
    "                if (i+1) is len(results):\n",
    "                    page.append(result)\n",
    "                    pages.append(widgets.VBox(children=tuple(page)))\n",
    "                elif (i)%10 is 0 and not i is 0:\n",
    "                    pages.append(widgets.VBox(children=tuple(page)))\n",
    "                    page = []\n",
    "                page.append(result)\n",
    "            \n",
    "#             SERP = widgets.VBox(children=(tuple([i for i in results])))\n",
    "#             children = [widgets.Text(description=name) for name in list]\n",
    "            SERP = widgets.Tab(children=pages)            \n",
    "        display(SERP)\n",
    "\n",
    "#----------------------------------------------------------------------------      \n",
    "    # ADVANCED SEARCH\n",
    "    else:\n",
    "        display('Zoeken..')\n",
    "        \n",
    "        # SELECTED DOCUMENT TYPES\n",
    "        types = []\n",
    "        if ad_check.value:\n",
    "            types.append('advertentie')\n",
    "        if ar_check.value:\n",
    "            types.append('artikel')\n",
    "        if io_check.value:\n",
    "            types.append('illustratie met onderschrift')\n",
    "        if fb_check.value:\n",
    "            types.append('familiebericht')\n",
    "        fields = []\n",
    "        \n",
    "        # SELECTED TEXT FIELDS\n",
    "        if title_check.value:\n",
    "            fields.append('title')\n",
    "        if text_check.value:\n",
    "            fields.append('text')\n",
    "        \n",
    "        # Search. The values for the slider and text are immediately inputted\n",
    "        res = search([types,text.value,fields,years.value], advanced=True)\n",
    "        clear_output()\n",
    "        results = result_page(text.value, res['hits']['total'], res['hits']['hits'])\n",
    "        \n",
    "        # Print the Search results\n",
    "        if results == []:\n",
    "            SERP = widgets.VBox(children=(widgets.HTML('', height='20px'),\n",
    "                                          widgets.HTML(\"<center>Geen zoekresultaten \\\n",
    "                                          zijn gevonden. Probeer het opnieuw</center>\")))\n",
    "        else:\n",
    "            pages = []\n",
    "            page = []\n",
    "            for i, result in enumerate(results):\n",
    "                if (i+1) is len(results):\n",
    "                    page.append(result)\n",
    "                    pages.append(widgets.VBox(children=tuple(page)))\n",
    "                elif (i)%10 is 0 and not i is 0:\n",
    "                    pages.append(widgets.VBox(children=tuple(page)))\n",
    "                    page = []\n",
    "                page.append(result)\n",
    "            SERP = widgets.Tab(children=pages)  \n",
    "        display(SERP)\n",
    "        \n",
    "        # update the type doc numbers\n",
    "        for i in doc_types:\n",
    "            doc_types[i].widget.value= doc_types[i].name+' ('+str(get_count(i,text.value,fields,years.value))+')'\n",
    "        \n",
    "        # DISPLAY TIMELINE\n",
    "        if timeline_check.value: \n",
    "            timeline_years = [int(hit['_source']['year']) for hit in res['hits']['hits']]\n",
    "            dates = [hit['_source']['date'] for hit in res['hits']['hits']]   \n",
    "            if timeline_years != []:\n",
    "                create_timeline(timeline_years, dates)\n",
    "        \n",
    "        #DISPLAY WORDCLOUD\n",
    "        if wordcloud_check.value:\n",
    "            total_text = []\n",
    "            for hit in res['hits']['hits']:\n",
    "                total_text.extend(hit['_source']['text'].split())\n",
    "            create_wordcloud(total_text, 50)\n",
    "\n",
    "\n",
    "        \n",
    "# Display the main items and set their submits/change response\n",
    "display(container)\n",
    "display(container_adv)\n",
    "\n",
    "# Set the widgets their response \n",
    "text.on_submit(handle_submit)\n",
    "search_button.on_click(handle_submit)\n",
    "advanced.observe(advanced_options,names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 4: Evaluation\n",
    "* Evaluate your results Let 2 persons assess the relevancy of the top 10 documents for 5 different queries. Compute Cohen's kappa. Determine the average precision at 10 for your system based on these 10 queries, and the two relevance assesments. Also plot the P@10 (for both judges) for each query, showing differences in hard and easy queries. Describe clearly how you solved differences in judgements. \n",
    "* Change the ranking of your system, compute the average precision at 10 using your 10 queries, compare the results to your old system, and EXPLAIN what is going on.\n",
    "\n",
    "Our 5 queries, with their description and guidelines:\n",
    "\n",
    "Query: Koningin opening museum, Subject: artikel\n",
    "Description: You want information about Dutch queens that have opened musea throughout the twentieth century.\n",
    "Guidelines: the article should be about a queen, not for example about the Queen's Commissioner. The article should be about a museum, not just about some opening somewhere.\n",
    "\n",
    "Judge 1: 1 2 3 7 8 9\n",
    "Judge 2: 1 2 7 8 9\n",
    "\n",
    "Query: Hitler dood, Subject: artikel\n",
    "Description: you want information about Hitler's death. You are interested in how he died, where he died and when he died.\n",
    "Guidelines: articles that only mention his death shortly without information about how and when are not relevant. The article should at least mention one of the three things (how, where, when).\n",
    "\n",
    "Judge 1: 5 6 7\n",
    "Judge 2: 5 6\n",
    "\n",
    "Query: geboren, Year facet: 1978, Subject: familiebericht \n",
    "Description: I want to know which people were born in the year 1978 Guidelines: The article should clearly state the date of birth and the person's name.\n",
    "\n",
    "Judge 1 -->1 2 3 4 5 7 8 9 10\n",
    "Judge 2 -->1 2 3 4 5 6 7 8 9 10\n",
    "\n",
    "Query: val Berlijnse muur, Year: 1975-1900, Subject: artikel\n",
    "Description: I am interested in articles about the end of the Berlin wall. Guidelines: articles should be about the end of the wall.\n",
    "\n",
    "Judge 1: 1 2 5 7 9\n",
    "Jduge 2: 1 2 5 7 9\n",
    "\n",
    "Query: robot voetbal, Year: 1975-1900, Subject: artikel\n",
    "Description: we are interested in articles about robots that play football. Guidelines: the articles should really be about robots and football, not just about robots, or just about football.\n",
    "\n",
    "Judge 1: 1 2 5 8\n",
    "Judge 2: 1 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "def cohens_kappa(bins):\n",
    "    \"\"\"\n",
    "    Given bins made by bin_evaluations, returns cohen\\'s kappa\n",
    "    \"\"\"\n",
    "    \n",
    "    total = bins[0]+bins[1]+bins[2]+bins[3]\n",
    "    po = (bins[0]+bins[3]) / total\n",
    "    \n",
    "    marginala = ((bins[3] + bins[2]) * (bins[3] + bins[1])) / total\n",
    "    marginalb = ((bins[0] + bins[1]) * (bins[0] + bins[2])) / total\n",
    "    pe = (marginala + marginalb) / total\n",
    "    \n",
    "    cohens_kappa = (po - pe) / (1 - pe)\n",
    "    return cohens_kappa\n",
    "    \n",
    "def precision(bins, agreement_necessary):\n",
    "    \"\"\"\n",
    "    Given bins made by bin_evaluations, returns precision\n",
    "    If second argument is True, document is only seen as\n",
    "    relevant if both judges think so; otherwise one of the \n",
    "    judges is enough\n",
    "    \"\"\"\n",
    "    if agreement_necessary:\n",
    "        correct = bins[3]\n",
    "    else:\n",
    "        correct = bins[3] + bins[2] + bins[1]\n",
    "    total = bins[0]+bins[1]+bins[2]+bins[3]\n",
    "    return correct/total\n",
    "    \n",
    "    \n",
    "def bin_evaluations(evaluations):\n",
    "    \"\"\"\n",
    "    Given a list of tuples of binary values which contain\n",
    "    relevance judgements by two judges in which 1 means \n",
    "    relevant, and 0 means non-relevant, returns a list\n",
    "    in which the 4 elements represent the amount of times\n",
    "    any combination has occurred.\n",
    "    \"\"\"\n",
    "    \n",
    "    # bins are 00, 01, 10, 11 in that order\n",
    "    bins = [0,0,0,0]\n",
    "    for evaluation in evaluations:\n",
    "        b = 0\n",
    "        if evaluation[0]:\n",
    "            b += 2\n",
    "        if evaluation[1]:\n",
    "            b += 1\n",
    "        bins[b] += 1\n",
    "    return bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_search_results(number_of_queries):\n",
    "    \"\"\"\n",
    "    Asks the user to submit a query using query_database() some amount \n",
    "    of times after which two judges can give their relevancy \n",
    "    assessments. Returns evaluations in a format that can be used for \n",
    "    bin_evaluations.\n",
    "    \"\"\"\n",
    "\n",
    "    print('After the query is resolved, you will be asked to rate the documents on relevancy.')\n",
    "    print('To do this, enter the numbers of the relevant results sperated by whitespace.')\n",
    "    print('For example, if only the first and third documents were relevant, enter \\'1 3\\' without the quotes.')\n",
    "    print('If more than ten documents are returned, ignore all but the first 10.\\n')\n",
    "    evaluations = []\n",
    "    for _ in range(number_of_queries):\n",
    "        query = raw_input('Query -->')#.split()\n",
    "        years  =raw_input('Years begin, end -->').split(', ')\n",
    "        years = tuple(years)\n",
    "        types = raw_input('Types artikel, advertentie, familiebericht, illustratie met onderschrift -->').split(', ')\n",
    "        fields = raw_input('Fields text, title -->').split(', ')\n",
    "        res = search([types,query,fields,years],advanced=True)\n",
    "        results = result_page(text.value, res['hits']['total'], res['hits']['hits'])\n",
    "        \n",
    "        # Print the Search results\n",
    "        if results == []:\n",
    "            SERP = widgets.VBox(children=(widgets.HTML('', height='20px'),\n",
    "                                          widgets.HTML(\"<center>Geen zoekresultaten \\\n",
    "                                          zijn gevonden. Probeer het opnieuw</center>\")))\n",
    "        else:            \n",
    "            pages = []\n",
    "            page = []\n",
    "            for i, result in enumerate(results):\n",
    "                if (i+1) is len(results):\n",
    "                    page.append(result)\n",
    "                    pages.append(widgets.VBox(children=tuple(page)))\n",
    "                elif (i)%10 is 0 and not i is 0:\n",
    "                    pages.append(widgets.VBox(children=tuple(page)))\n",
    "                    page = []\n",
    "                page.append(result)\n",
    "            \n",
    "            SERP = widgets.Tab(children=pages)            \n",
    "        display(SERP)\n",
    "        \n",
    "        print('Indicate which documents were relevant:')\n",
    "        judge1_input = raw_input('Judge 1 -->').split()\n",
    "        judge2_input = raw_input('Judge 2 -->').split()\n",
    "        for i in range(1, 11):\n",
    "            if str(i) in judge1_input:\n",
    "                assessment1 = 1\n",
    "            else:\n",
    "                assessment1 = 0\n",
    "            if str(i) in judge2_input:\n",
    "                assessment2 = 1\n",
    "            else:\n",
    "                assessment2 = 0\n",
    "            evaluations.append((assessment1, assessment2))\n",
    "        print(\"\\nP@10)\n",
    "    \n",
    "    bins = bin_evaluations(evaluations)\n",
    "    print('\\nThe average P@10 if we require agreement for correctness: ' + str(precision(bins, 1)))\n",
    "    print(\"The average P@10 if we require a single \\'relevant\\' assessment for correctness: \" + str(precision(bins, 0)))\n",
    "    print(\"Cohen\\'s Kappa was: \" +str(cohens_kappa(bins)))\n",
    "    return evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the query is resolved, you will be asked to rate the documents on relevancy.\n",
      "To do this, enter the numbers of the relevant results sperated by whitespace.\n",
      "For example, if only the first and third documents were relevant, enter '1 3' without the quotes.\n",
      "If more than ten documents are returned, ignore all but the first 10.\n",
      "\n",
      "Query -->Koningin opening museum\n",
      "Years begin, end -->1900, 2000\n",
      "Types artikel, advertentie, familiebericht, illustratie met onderschrift -->artikel\n",
      "Fields text, title -->text, title\n",
      "Indicate which documents were relevant:\n",
      "Judge 1 -->1 2 3 7 8 9\n",
      "Judge 2 -->1 2 7 8 9\n",
      "Query -->Hitler dood\n",
      "Years begin, end -->1900, 2000\n",
      "Types artikel, advertentie, familiebericht, illustratie met onderschrift -->artikel\n",
      "Fields text, title -->text, title\n",
      "Indicate which documents were relevant:\n",
      "Judge 1 -->5 6 7\n",
      "Judge 2 -->5 6\n",
      "Query -->geboren\n",
      "Years begin, end -->1978, 1978\n",
      "Types artikel, advertentie, familiebericht, illustratie met onderschrift -->familiebericht\n",
      "Fields text, title -->text, title\n",
      "Indicate which documents were relevant:\n",
      "Judge 1 -->1 2 3 4 5 7 8 9 10\n",
      "Judge 2 -->1 2 3 4 5 6 7 8 9 10\n",
      "Query -->robot voetbal\n",
      "Years begin, end -->1975, 2000\n",
      "Types artikel, advertentie, familiebericht, illustratie met onderschrift -->artikel, advertentie\n",
      "Fields text, title -->text, title\n",
      "Indicate which documents were relevant:\n",
      "Judge 1 -->1 2 5 8\n",
      "Judge 2 -->1 2\n",
      "Query -->val Berlijnse muur\n",
      "Years begin, end -->1975, 2000\n",
      "Types artikel, advertentie, familiebericht, illustratie met onderschrift -->artikel\n",
      "Fields text, title -->text, title\n",
      "Indicate which documents were relevant:\n",
      "Judge 1 -->1 2 5 7 9\n",
      "Judge 2 -->1 2 5 7 9\n",
      "\n",
      "The average P@10 if we require agreement for correctness: 0.46\n",
      "The average P@10 if we require a single 'relevant' assessment for correctness: 0.56\n",
      "Cohen's Kappa was: 0.800637958533\n"
     ]
    }
   ],
   "source": [
    "evaluations = evaluate_search_results(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {
    "08e996b394484809a12f889cd574b22b": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "4d398c9a9f7a4e599842ef2d502b6b78": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "682fb279bb794590aec84af83c6d7b26": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "7edca45557144eb6bac0f4ed4bb687b8": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "907091c39ed046b1871408cc83aafbba": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "9fa7197b60d34cf3a3c4c33ed8582fa4": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "b7a51ae6164748caa73209dac32acbda": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "bb724787edde4e5d8aad9af3d0e96efc": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    },
    "c04c1fe6629b44d7b5613efad951ae3d": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "e7276aaed08e44968433fd012c1d318c": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    },
    "f18992f585e2486cabb20211724af86a": {
     "views": [
      {
       "cell_index": 23
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
